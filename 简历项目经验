项目名称：Ansible 配置管理 
项目背景：由于公司业务环境需求在不断扩大，已经无法满足当前需求，所以公司新采购10多台服务器，要部署nginx服务，如果一台台装会浪费大量时间，不值得。
项目任务：在开会讨论后决定，让我使用ansiable playbook部署nginx服务（修改端口，并带有vars变量）对配置文件进行标准化，批量化修改，完成项目部署。
我的职责：
	1. 统一管理线上部分相同应用的配置文件，防止人为修改错误，导致应用运行问题；
	2. 针对公司环境，使用 Ansible 进行统一配置管理；
	3. 实现同步状态批量修改不同服务器的不同应用的配置文件，防止改错或漏改等问题。

项目名称：Ansible 配置管理 
项目背景：公司有50多台服务器，运维人员有时会批量修改一些文件，或者分发一些文件，有次说新增用户名和密码对上述主机，做权限访问控制，由于重复性的工作会浪费大量时间，不值得。
项目任务：领导开会给我布置任务，对配置文件进行标准化目录，批量化修改，讨论最后用Ansible批量执行完成任务。
我的职责：
	1. 针对公司环境，使用Ansible进行统一配置管理；
	2. 实现同步状态批量修改不同服务器的不同应用的配置文件，防止改错或漏改等问题。

项目名称：Ansible 配置管理 
项目背景：公司有30多台服务器，运维人员有时会批量修改一些文件，或者分发一些文件，记得有次做域名解析在hosts文件添加配置，对于这种重复性的工作会浪费大量时间，不值得。
项目任务：领导开会决定让我对配置文件进行标准化目录，批量化修改，讨论最后用Ansible批量执行完成任务。
我的职责：
	1. 统一管理线上部分相同应用的配置文件，防止人为修改错误，导致应用运行问题；
	2. 针对公司环境，使用 Ansible 进行统一配置管理；
	3. 实现同步状态批量修改不同服务器的不同应用的配置文件，杜绝人为错误，防止改错或漏改等问题。


项目名称：Zabbix全网服务器监控方案
项目描述：由于公司内部监控体系不完善，某服务器宕机或者服务突然中止，对于运维人员来说是无法第一时间感知的，对用户体验较差。
项目任务：领导要求我把公司服务器和业务作相应的监控，经讨论决定使用zabbix监控所有主机，因为zabbix 操作简单易用，功能全面。
3. 对硬件的监控:对 CPU 温度进行。
我的职责：
1. 对硬件的监控：主要对 CPU、内存、网络IO和硬盘利用率情况进行监控；
2. 对服务器进程监控：主要监控服务的端口以及进程等；
3. 搭建监控系统能及时通过邮件，短信等方式反馈给运维工作人员，让运维人员第一时间发现问题，及时处理故障，为公司业务带来更好的服务，让用户体验感更佳；


项目名称：MySQL主从复制+MHA高可用，实现数据备份及恢复
项目背景：公司刚开始的时候数据库没有做高可用，我们在使用脚本来进行主从切换，一旦宕机，后果不堪设想。
项目任务：领导要求我拿出合理的方案，我们最后开会讨论拿出MHA方案，原因是DBA之前公司使用的这套Mysql架构。
我的职责：
1.保证数据安全，针对数据库单点问题。
2.根据实际情况开会讨论，确认高可用方案，使用MHA做故障切换。
3.针对MHA进行研究。
4.根据需求，选用数据库备份方案，并进行恢复测试。
5.做好数据恢复解决方案。

项目解决：
1. 保证数据安全，针对数据库单点问题；
2. 根据实际情况开会讨论，确认高可用方案，使用MHA做故障切换；
3. 使用 MySQL 主从复制功能，定时备份数据；
4. 主故障时，通过 MHA 做主从提升，在 30 秒内进行切换，最大程度保证数据一致性；
5. 根据需求，选用数据库备份方案，并进行恢复测试；
6. 做好数据恢复解决方案；
7. 通过 Atlas 管理节点，让所有的写操作到主库，读操作到从库。 

负载均衡高可用方案
1. 为解决线上负载均衡服务单点问题；
2. 针对性制定高可用方案，解决单点问题；
3. 负载均衡使用 keepalived 做高可用；
4. 解决了负载均衡故障后，整个集群无法提供向外提供服务的问题。 

数据备份方案
1. 公司重要数据备份混乱、未及时备份及误删状况，给工作带来不便；
2. 针对以上现象和领导提出统一备份数据方案，并制定意外恢复方案；
3. 所有服务器数据，定时备份，压缩并推送到主备份服务器，主备份服务器另将数据备份到
备备份服务器，重要数据使用sersync实时备份；
4. 备份服务器通过脚本进行数据检查，重要数据进行还原测试；
5. 定期将IDC机房数据备份到公司内部服务器，防止机房数据丢失。



专业技能	
1.熟悉编写shell脚本，熟练使用awk、sed、grep等脚本辅助工具，可独立编写脚本，了解Python；
2 熟悉MySQL数据库备份，数据库主从搭建并实现高可用；
3.熟悉Linux系统主流开源服务keepalived、lvs/nginx/haprox、配置及排错，如Nginx，Apache等服务；
4.熟练使用自动化运维工具Ansible、Puppet等；
5.熟练使用zabbix，prometheus监控工具使用。
6.熟悉持续集成（CI），持续交付（CD）和devops方面知识，会devops环境搭建使用。
7.熟练搭建ELK搜索引擎，优化、故障处理；
8.熟练掌握docker、Kubernetes知识体系架构及各个组件用途，熟练环境部署、完成应用升级、回滚、并有一定的排错能力；


个人技能
了解kvm及docker 等虚拟化技术
zabbix等监控软件安装配置，能够配置对web,数据库，负载均衡，存储等服务器进行监控
linux系统安全及其防火墙iptables部署优化，并根据生产环境具体要求进行配置
熟悉mysql基本的sql语句，日常应用调优，对mysql存储过程有一定了解
mysql数据库的日常定时备份和（增量）恢复
mysql数据库应用，包括主从同步，主主同步集群的部署及读写分离的实现和配置
lvs+keepalived四层负载均衡集群及haproxy，nginx七层负载均衡与反向代理构建及优化
lnmp,lamp架构，tomcat，php等Web服务的构建及优化
shell编程，熟练使用shell及其文本处理工具grep,awk，sed，cut，tr等进行服务器日志分析，监控，数据备份等日常工作
部署ssh key结合rsync备份和文件分发解决方案，了解puppet分发部署
nfs共享存储的部署应用及rsync,inotify,等数据(实时)同步工具的使用
centos/rhel等linux系列系统安装及性能调优，安全优化


项目名称：全网数据备份方案
项目背景：由于在我来公司之前，数据发生过丢失的情况，对此，技术主管要求我备份全网数据，包括网站目录及访问日志，做统一备份。
项目任务：根据项目需求，制定项目方案。备份网站目录及访问日志，确保定时备份后的数据必须完整正确，在备份服务器上对备份的数据进行检查，把备份的成功及失败结果信息发给系统管理员邮箱中；搭建NFS存储实现web服务器网站图片、附件共享；NFS存储数据实时备份。
你的成就：解决了数据丢失的问题。



工作经历（案例一）
工作时间：2017-02到至今

公司名称：简历本信息技术有限公司 | 所在部门： | 所在岗位：Linux运维工程师

工作描述：
1，负责服务器日常运维工作，以及处理7*24小时的突发应急事件； 
2，负责系统部署上线，系统优化，日常更新，监控和维护工作；
3，研究业务系统架构、实现性能优化，提高系统的安全性和健壮性；
4， 按照制定的流程及规范实行运维操作，协助改进运维文档的维护流程，提高服务运行质量；
5，负责数据备份、数据监控、应急响应、故障排除、编写数据分析报告等。
6，负责平台的搭建、部署、监控、调优、升级、日常维护和管理工作； 
7，负责处理系统方面日常变更、控制突发情况，对疑难问题进行分析并解决；
8，支持服务器系统部署、应用调整，提高操作效率，增强系统可用性；
9，保障服务器与数据库的稳定运行，检查并消除系统安全隐患；
10，按时完成领导交代的其他相关工作。

工作经历（案例二）
工作时间：2015-07到2017-07

公司名称：简历本人才咨询有限公司 | 所在部门： | 所在岗位：linux运维工程师

工作描述：
1.web集群的搭建以及对服务器集群的?常运?维护，配置管理，故障应急处理；
2.部署 zabbix 监控服务，负责监控公司的各类服务系统运?状态并进?维护；
3.对系统、线上?站进?监控并配置报警，7*24?时接收报警信息并处理；
4.负责编写shell对mysql进?日常备份；
5.利用keepalived解决单点故障;
6.协助研发?员完成项?测试；
7.编写管理维护相关Shell脚本（部署、日志处理、监控、备份）等脚本；
8.负责公司LB+HA（LVS/Nginx+keepalive）集群的安装及?常维护。
9.负责MySQL数据库的搭建部署，并MySQLdump实现数据的备份，利用中间件amoeba实现读写分离；
10.负责公司内部的Openstack云平台的搭建、运行和维护

工作经历（案例三）
工作时间：2016-08到2017-05

公司名称：简历本网络科技有限公司 | 所在部门： | 所在岗位：linux运维工程师

工作描述：
职位名称：linux运维
1.例行检查，进行问题和追查，并解决可能得隐患
2.熟系服务器资源状况，做到批量管理，自动化管理
3.负责mysql数据库数据的日常备份和还原测试
4.看监控，实时了解服务器设备的运行状态
5.负责服务器的搭建，维护
，调优，故障排除
6.及时处理并回复相关的服务器报警信息
7.积极配合上级领导分发的工作并完成

工作经历（案例四）
工作时间：2017-01到2017-03

公司名称：简历本网络科技有限公司 | 所在部门： | 所在岗位：linux运维工程师

工作描述：
部门：研发部
参与人数：11人
责任描述：负责平台的部署，搭建，优化，数据备份，服务器的运行
项目描述：DSP（Demand-Side Platform），就是需求方平台，以精准营销[1] 为核心理念。这一概念起源于网络广告发达的欧美，是伴随着互联网和广告业的飞速发展新兴起的网络广告领域,DSP传入中国，迅速在国内成为热潮，成为推动中国网络展示广告RTB市场快速发展的动力之一，dsp将要成为SEM后的一个广告模式。

工作内容：
负责redis集群的部署安装调优
负责redis主从模式的部署安装和优化
负责LVS-DR模式的负载均衡


项目经验（案例一）
项目时间：2016-07 - 2016-09

项目名称：LAMP论坛搭建 | 项目工具：Linux；Apache；Mysql；php

项目描述：
项目介绍
使用Redhat Enterprise Linux 5.3、httpd-2.2.11、mysql、php-5.2.9 等软件，编译安装Apache、Mysql、PHP，使Apache支持PHP，PHP连接上Mysql，然后搭建LAMP环境下的PHP论坛，使其可以解析动静态页面。开源软件免费且使用源码包安装可方便定制，中小型网站比较适用。
我的职责
mysql源码包的编译安装，编译过程中先安装cmake（源码包）工具，然后使用cmake工具编译mysql，最后make安装。

项目经验（案例二）
项目时间：2016-02 - 2016-05

项目名称：电商网络环境扩建

项目描述：
　　服务器当前环境无法满足需求，公司决定进行服务器环境改造。实现高可用、负载均衡为核心的目的。快速、高效的发挥所有服务器的性能，使公司的业务平台平稳运行。
　　根据项目需求，项目组制定项目计划：
　　搭建Nginx+keepalived+tomcat实现tomcat高可用性负载均衡，实现高性能、高可用、高并发访问及动静分离的web集群方案。有前置nginx 做反向代理，采用nginx的location做动静分离，将静态HTML网页、图片、JS、CSS等使用后端nginx或apache处理，以便得到更快的速度；将.jsp、.jspx、.do等交给后端tomcat来处理，从而实现动静分离的应用。通过Keepalived检测web集群服务器的状态，Keepalived提供健康检查和状态监测。实现群集高可用性能。
　　存储服务搭建ＭFS分布式文件系统实现服务器之间的访问不再似一对多的关系，而是多对多的关系这样可以是性能得到大幅度提升。
通过搭建zabbix监控系统对服务和设备状态进行监控

我的职责：
　　参与项目方案的实施、主要在项目中搭建Ｎginx＋Keepalived＋Ｔomcat（支持Jsp,do）实现高可用负载均衡，搭建ＭFS分布式文件系统

个人简历-项目经验

要点

Kubernetes 生产应用

云主机弹性伸缩
日志收集平台 ELK
监控平台 从 zabbix 到 prometheus
代码发布平台 Jenkins
堡垒机 jumpserver
打点服务应用 prometheus

 Kubernetes 生产应用

项目经验：
服务对弹性伸缩, deployment利用Horizontal Pod Autoscaling实现对pod实现对内对外提供服务, 利用 ingress 和 service 实现
权限管理, 利用 namespace和rdac实现
helm 软件包管理工具
node 节点的弹性伸缩, 利用对云主机的弹性伸缩实现

监控
kube-prometheus
日志收集
节点上运行一个 agent 来收集日志,但 DaemonSet 模式下

阿里云日志服务
FELK
pod 中包含一个 sidecar 容器来收集应用日志

在每个 pod 中添加一个 fluentd 或 filebeat 容器收集日志传输到外部ELK 中
直接在应用程序中将日志信息推送到采集后端

项目名称：代码发布
项目经验：
jenkins shell（目前比较low）
可用 drone 或 jenkins-pipeline 。
自己写一个。已经有大概思路。

<a id = "ecs"> 云主机弹性伸缩。</a>
对主机的弹性伸缩服务，这个是云服务商提供的服务。\
弹性伸缩主要是根据设置的伸缩规则，在业务需求增长时自动为您增加 ECS 实例以保证计算能力，在业务需求下降时自动减少 ECS 实例以节约成本。\
产品主要通过在SLB后面挂载 ECS 。实现对cpu或内存使用率的监控，当内存或cpu超过一定的阈值，利用之前定义的伸缩策略，利用之前制作好到镜像进行伸缩 ECS 。\
带来下面问题

问题
新发布代码无法在老镜像中。如果弹性伸缩的话，新增的 ECS 中的代码就和线上代码不一致了。

解决
个人觉得比 low，这样也使发布比较重。但在 Kubernetes 中就不存在这样的问题了。

在发布代码后，调用云服务商的API，给新 ECS 打镜像、修改项目的弹性伸缩策略、把新镜像id替换老镜像id。

<a id = "elk"> 日志收集 </a>
elk+kafka
a. filebeat 收集 nginx 的日志并把日志发给 logstash
b. logstash 对日志进行字段拆分并写到 elasticicsearch 。如果利用到kafka ，就在写到 elasticicsearch 之前，先写到 kafka ，之后elasticicsearch 从kafka 中获取数据。
c. 利用 kibana 进行展示。
d. 在 kibana 根据不同的业务，提前配置好对 request_time、upstream_time、status_code 等等的 dashboard, 方便定位问题。
e. 告警：
写好脚本，定期检查不同业务的 request_time、upstream_time、status_code 。如果超时或 status_code 为 5XX 就钉钉告警
程序部分日志收集和告警
要求：

网关 nginx 服务产生 request_id ,这个请求后面的一系列请求都带上这个request_id 写日志. 
目地
方便定位问题。

当nginx 中出现 5xx 等错误时，根据这个请求的 request_id，可以找到程序中对应的一系列请求，从而快速定位具体问题在哪里。
资源：
考虑到资源问题，目前仅仅收集 warn/ error / fatal 三个等级的程序日志，导入到 elk 中。根据 request_id 快速定位程序问题。

告警：

定时任务，统计最近1分钟，如果某个项目出现10个 error 或者出现过 fatal 就告警。
每天统计项目出现的 warn 次数。发邮件。
项目 warn 较多的（500条warn），额外会钉钉发告警，让开发处理一下

<a id = "prometheus"> 监控 </a>
从 mysql+zabbix+grafana+微信/钉钉 到 prometheus+grafana+alertmanager + 钉钉

主要监控点
cpu 使用率
内存使用量/使用率
服务器负载
磁盘容量/io
网络流量
tcp连接数
来源IP连接数
访问IP连接数
对服务的监控：''
redis : cpu，内存使用量、hit、miss 、get 、 set、ops ...
elasticsearch: cpu、jvm、内存、gc、indics、健康状态、 ops ...
mongodb: cpu、mem、ops ...
之所以迁移到 prometheus

prometheus 对资源的要求非常低。就一个二进制问题，运行起来就可以了。
当 zabbix 监控超过100台服务器之后，查看监控的时候就明显慢了。
prometheus 添加告警更加清晰方便。
<a id = "jenkins"> jenkins 代码发布 </a>
对开发要求：
规定所有开发，所有编译过程，都写一个 `makefile` 。我这边仅仅需要 `make build` 即可
大致流程：
先从 git 仓库获取根据对应的 tag 或 branch 获取代码。
利用 jenkins 的 shell 功能，进行 make build
获取 build 后的代码， rsync 到服务器。
重启 supervisor 服务。
健康检查；sleep 3s，查看端口和进程是否正常。同时请求健康检查接口，查看服务是否正常。
到这里这个发布完成。但同时会触发下面步骤。后台运行。
利用 api 对新发布的项目中的某一个 ecs 进行打镜像. 一般10分钟左右
修改弹性伸缩策略的的镜像 ID 为a步骤产生的镜像 ID 。
发钉钉和邮件提醒。主要包括项目名称、修改前后的镜像名称。
<a id = "jumpserver"> 堡垒机 jumpserver </a>
目的：
目前还没有把所有的程序日志收集，偶尔开发到服务器查看相应的debug日志。
开发需要到服务器，就带来权限管理问题了。用它主要就是为了解决这个问题。
优点：
不同的开发，给不同的访问服务器的权限
资源统一管理。
操作审计等等
<a id = "point"> 打点服务，定位资源使用情况 </a>
prometheus+pushgateway+grafana+alertmanager+钉钉

目的
经常会遇到如下问题， 某个服务、资源的 cpu 或者内存飙高。为了清楚了解。这些资源为飙高，是什么服务导致，我们就加入了打点服务。

方案：
程序在调用其依赖的资源时，往时序数据库打一个点。
prometheus 作为时序数据库。
pushgateway 作为 prometheus时序数据库的网关。
grafana 做展示
alertmanager + 钉钉，实现告警


项目名称：gitlab+jenkins搭建代码发布平台
项目经验：

工作内容：
负责jenkins平台的部署安装调优，测试。
负责git
jenkins shell（目前比较low）
可用 drone 或 jenkins-pipeline 。
自己写一个。已经有大概思路。

搭建统一管理平台jumpserver


项目经验（案例一）
项目时间：2017-06 - 2017-07

项目名称：LB + HA 集群 | 项目工具：Linux；ipvsadm；Piranha；Apache

项目描述：
项目介绍
搭建以Linux为操作系统的服务器集群。通过LVS的DR模式，实现访问Apache网站时，支持多种分发策略的四层负载均衡。缓解单台Apache服务器的访问压力，提高访问上限。DR模式可缓解Director服务器的压力，提高工作效率。同时通过Piranha软件在两台Director服务器间建立心跳线，实现Director服务器的双机热备，避免单点故障造成的集群瘫痪。
我的职责
在RealSercer服务器上安装并搭建Apache网站环境，设置IP地址，修改内核参数。分别在主备Director服务器上安装ipvsadm和Piranha。设置LVS的DR模式，选择适合的分发策略（wlc），设置VIP和DIP地址，分别测试主备Director服务器均可单独工作实现负载均衡。配置Piranha的配置文件。部署浮动资源（VIP、IPVS策略）。测试主备服务器实现双机热备


自我评价（案例一）
1、熟悉redhat，centos，windows系统，对bash python脚本较为熟悉,具有同时管理超过四千台以上服务器的运维管理经验。
2、具有自建小型机房的网络设计及运维经验，熟悉cisco router cisco swith cisco ASA Firewall Mcafee IPS，Array 四七层负载均衡网络设备，熟悉TCP/IP协议，擅于网络抓包分析。
3、具有服务器虚拟化经验，对服务器主流的kvm vmware esx 较为熟悉。
4、擅长服务器的安全加固，有成熟的DDOS解决方案，熟悉常见的DDOS攻击。
5、擅长运维架构的制定web db 集群的实施,熟悉python php bind apache nginx haproxys lvs tomcat memcached zabbix rsync mfs redis scribed drbd openvpn mysql mongodb docker elk flume hadoop hive 及django web 开发、熟悉http协议。
6、本人个性沉稳，做事注重条理性,重视工作方法，喜欢钻研，自信和执着是我的原则,沉着和乐观是我处事的态度，接受能力和执行能力强，诚实有责任心，如有幸被贵公司录用我将会竭尽全力为贵公司奉献微薄之力。

